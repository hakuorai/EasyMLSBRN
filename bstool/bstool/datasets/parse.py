import ast
import math
from collections import defaultdict
from json.decoder import JSONDecodeError

import bstool
import cv2
import geopandas
import mmcv
import numpy as np
import pandas
import pycocotools.mask as maskUtils
import rasterio as rio
import shapely
import tqdm
from pycocotools.coco import COCO
from shapely import affinity
from shapely.geometry import MultiPolygon, Polygon


def shp_parse(
    shp_file,
    geo_file,
    src_coord="4326",
    dst_coord="pixel",
    keep_polarity=True,
    clean_polygon_flag=False,
):
    """parse shapefile

    Args:
        shp_file (str): shapefile
        geo_file (str or rio class): geometry information
        src_coord (str, optional): source coordinate system. Defaults to '4326'.
        dst_coord (str, optional): destination coordinate system. Defaults to 'pixel'.

    Returns:
        list: parsed objects
        det, seg = result
    """
    try:
        shp = geopandas.read_file(shp_file, encoding="utf-8")
    except:
        print("Can't open this shapefile: {}".format(shp_file))
        return []

    if isinstance(geo_file, str):
        geo_img = rio.open(geo_file)

    dst_polygons = []
    dst_properties = []
    for idx, row_data in shp.iterrows():
        src_polygon = row_data.geometry
        src_property = row_data[:-1]

        if src_polygon.geom_type == "Polygon":
            dst_polygons.append(
                bstool.polygon_coordinate_convert(
                    src_polygon, geo_img, src_coord, dst_coord, keep_polarity
                )
            )
            dst_properties.append(src_property.to_dict())
        elif src_polygon.geom_type == "MultiPolygon":
            for sub_polygon in src_polygon:
                dst_polygons.append(
                    bstool.polygon_coordinate_convert(
                        sub_polygon, geo_img, src_coord, dst_coord, keep_polarity
                    )
                )
                dst_properties.append(src_property.to_dict())
        else:
            raise (RuntimeError("type(src_polygon) = {}".format(type(src_polygon))))

    objects = []
    for idx, (dst_polygon, dst_property) in enumerate(zip(dst_polygons, dst_properties)):
        object_struct = dict()

        if clean_polygon_flag:
            if not dst_polygon.is_valid:
                continue
            if dst_polygon.geom_type not in ["Polygon", "MultiPolygon"]:
                continue

        object_struct["mask"] = bstool.polygon2mask(dst_polygon)
        xmin, ymin, xmax, ymax = dst_polygon.bounds
        object_struct["bbox"] = [xmin, ymin, xmax, ymax]
        object_struct["polygon"] = dst_polygon
        object_struct["property"] = dst_property

        objects.append(object_struct)

    return objects


def lingxuan_json_parser(json_file):
    """parse the json file generated by lingxuan

    Args:
        json_file (str): file path
    """
    try:
        content = mmcv.load(json_file)
    except JSONDecodeError:
        return []

    objects = []
    building_num = len(content["foot"])
    for idx in range(building_num):
        object_struct = dict()
        footprint_mask = content["foot_corner"][str(idx)]
        footprint_mask = np.array(footprint_mask).reshape(1, -1).tolist()[0]
        footprint_polygon = bstool.mask2polygon(footprint_mask)

        building_height = content["buildHeight"][str(idx)]

        xoffset = content["xyoffset"][str(idx)][0]
        yoffset = content["xyoffset"][str(idx)][1]
        ignore = content["ignoreFlag"][str(idx)]

        if not (isinstance(xoffset, (float, int)) and isinstance(yoffset, (float, int))):
            xoffset, yoffset = 0, 0
        object_struct["polygon"] = footprint_polygon
        object_struct["property"] = {
            "Id": idx,
            "Floor": building_height // 3,
            "xoffset": xoffset,
            "yoffset": yoffset,
            "ignore": ignore,
        }

        objects.append(object_struct)

    return objects


def mask_parse(mask_file, subclasses=(1, 3), clean_polygon_flag=False, with_opencv=True):
    """parse mask image

    Args:
        mask_file (str or np.array): mask image
        subclasses (tuple, optional): parse which class. Defaults to (1, 3).

    Returns:
        list: list of objects
    """
    if isinstance(mask_file, str):
        mask_image = cv2.imread(mask_file)
    else:
        mask_image = mask_file

    if mask_image is None:
        if isinstance(mask_file, str):
            print("Can not open this mask (ignore) file: {}".format(mask_file))
        else:
            print("Can not handle mask image (np.array), it is empty")
        return []

    sub_mask = bstool.generate_subclass_mask(mask_image, subclasses=subclasses)
    if with_opencv:
        polygons = bstool.generate_polygon_opencv(sub_mask)
    else:
        polygons = bstool.generate_polygon(sub_mask)

    objects = []
    for polygon in polygons:
        object_struct = dict()
        if clean_polygon_flag:
            if not polygon.is_valid:
                continue
            if polygon.geom_type not in ["Polygon", "MultiPolygon"]:
                continue
        object_struct["mask"] = bstool.polygon2mask(polygon)
        if len(object_struct["mask"]) == 0:
            continue
        object_struct["polygon"] = polygon
        objects.append(object_struct)

    return objects


def bs_json_parse(json_file, fix_height=False):
    """parse json file

    Args:
        json_file (str): json file

    Returns:
        list: list of objects
    """
    annotations = mmcv.load(json_file)["annotations"]
    objects = []
    for annotation in annotations:
        object_struct = {}
        roof_mask = annotation["roof"]
        roof_polygon = bstool.mask2polygon(roof_mask)
        roof_bound = roof_polygon.bounds
        footprint_mask = annotation["footprint"]
        footprint_polygon = bstool.mask2polygon(footprint_mask)
        footprint_bound = footprint_polygon.bounds
        building_xmin = np.minimum(roof_bound[0], footprint_bound[0])
        building_ymin = np.minimum(roof_bound[1], footprint_bound[1])
        building_xmax = np.maximum(roof_bound[2], footprint_bound[2])
        building_ymax = np.maximum(roof_bound[3], footprint_bound[3])

        building_bound = [building_xmin, building_ymin, building_xmax, building_ymax]

        xmin, ymin, xmax, ymax = list(roof_bound)
        bbox_w = xmax - xmin
        bbox_h = ymax - ymin
        object_struct["bbox"] = [xmin, ymin, bbox_w, bbox_h]
        object_struct["roof_bbox"] = object_struct["bbox"]
        xmin, ymin, xmax, ymax = list(footprint_bound)
        bbox_w = xmax - xmin
        bbox_h = ymax - ymin
        object_struct["footprint_bbox"] = [xmin, ymin, bbox_w, bbox_h]
        xmin, ymin, xmax, ymax = list(building_bound)
        bbox_w = xmax - xmin
        bbox_h = ymax - ymin
        object_struct["building_bbox"] = [xmin, ymin, bbox_w, bbox_h]

        object_struct["roof_mask"] = roof_mask
        object_struct["footprint_mask"] = footprint_mask
        object_struct["ignore_flag"] = annotation["ignore"]
        object_struct["offset"] = annotation["offset"]
        object_struct["building_height"] = annotation["building_height"]

        if math.isnan(object_struct["building_height"]):
            if fix_height:
                object_struct["building_height"] = 3.0
            else:
                continue

        object_struct["segmentation"] = roof_mask
        object_struct["label"] = 1
        object_struct["iscrowd"] = object_struct["ignore_flag"]

        objects.append(object_struct)

    if len(objects) == 0:
        print("The heights of this image are all nan, please fix them")

    return objects


def urban3d_json_parse(json_file):
    """parse json file

    Args:
        json_file (str): json file

    Returns:
        list: list of objects
    """
    annotations = mmcv.load(json_file)["annotations"]
    objects = []
    for annotation in annotations:
        object_struct = {}
        roof_mask = annotation["roof"]
        roof_polygon = bstool.mask2polygon(roof_mask)
        roof_bound = roof_polygon.bounds
        footprint_mask = annotation["footprint"]
        footprint_polygon = bstool.mask2polygon(footprint_mask)
        footprint_bound = footprint_polygon.bounds
        building_xmin = np.minimum(roof_bound[0], footprint_bound[0])
        building_ymin = np.minimum(roof_bound[1], footprint_bound[1])
        building_xmax = np.maximum(roof_bound[2], footprint_bound[2])
        building_ymax = np.maximum(roof_bound[3], footprint_bound[3])

        building_bound = [building_xmin, building_ymin, building_xmax, building_ymax]

        xmin, ymin, xmax, ymax = list(roof_bound)
        bbox_w = xmax - xmin
        bbox_h = ymax - ymin
        object_struct["bbox"] = [xmin, ymin, bbox_w, bbox_h]
        object_struct["roof_bbox"] = object_struct["bbox"]
        xmin, ymin, xmax, ymax = list(footprint_bound)
        bbox_w = xmax - xmin
        bbox_h = ymax - ymin
        object_struct["footprint_bbox"] = [xmin, ymin, bbox_w, bbox_h]
        xmin, ymin, xmax, ymax = list(building_bound)
        bbox_w = xmax - xmin
        bbox_h = ymax - ymin
        object_struct["building_bbox"] = [xmin, ymin, bbox_w, bbox_h]

        object_struct["roof_mask"] = roof_mask
        object_struct["footprint_mask"] = footprint_mask
        object_struct["offset"] = annotation["offset"]
        object_struct["building_height"] = annotation["building_height"]

        object_struct["segmentation"] = roof_mask
        object_struct["label"] = 1

        objects.append(object_struct)

    return objects


class COCOParse:
    """parse coco format file by COCO API"""

    def __init__(self, anno_file, classes=[""]):
        self.anno_info = dict()
        self.coco = COCO(anno_file)
        catIds = self.coco.getCatIds(catNms=classes)
        imgIds = self.coco.getImgIds(catIds=catIds)

        for idx, imgId in enumerate(imgIds):
            img = self.coco.loadImgs(imgIds[idx])[0]
            annIds = self.coco.getAnnIds(imgIds=img["id"], catIds=catIds, iscrowd=None)
            anns = self.coco.loadAnns(annIds)

            self.anno_info[img["file_name"]] = anns

    def __call__(self, image_fn):
        return self.anno_info[image_fn]


class BSPklParser:
    """parse the pkl file (result file)"""

    def __init__(
        self,
        anno_file,
        pkl_file,
        iou_threshold=0.1,
        score_threshold=0.05,
        min_area=500,
        with_offset=False,
        with_height=False,
        gt_roof_csv_file=None,
        replace_pred_roof=False,
        replace_pred_offset=False,
        offset_model="footprint2roof",
        merge_splitted=True,
    ):
        self.iou_threshold = iou_threshold
        self.score_threshold = score_threshold
        self.min_area = min_area
        self.with_offset = with_offset
        self.with_height = with_height
        self.offset_model = offset_model

        self.replace_pred_roof = replace_pred_roof
        self.replace_pred_offset = replace_pred_offset

        if not self.with_offset:
            if self.with_height:
                raise (
                    RuntimeError(
                        "not support with_offset={}, with_height={}".format(
                            self.with_offset, self.with_height
                        )
                    )
                )

        # load pkl file
        if isinstance(pkl_file, str):
            results = mmcv.load(pkl_file)
        else:
            results = pkl_file

        # load coco annotation file
        coco = COCO(anno_file)
        # img_ids = coco.get_img_ids()
        img_ids = coco.getImgIds()

        self.objects = dict()
        self.building_with_coord = defaultdict(dict)
        # convert the result information to the dict format
        for idx, img_id in tqdm.tqdm(enumerate(img_ids)):
            # info = coco.load_imgs([img_id])[0]
            info = coco.loadImgs([img_id])[0]
            img_name = bstool.get_basename(info["file_name"])
            sub_fold, ori_image_name, coord = bstool.get_info_splitted_imagename(img_name)

            result = results[idx]

            self.building_with_coord[ori_image_name][coord] = self._convert_items(result)
            self.objects[img_name] = self.building_with_coord[ori_image_name][coord].copy()

        print("========== begin to merge the polygons in pkl ==========")
        if merge_splitted:
            self.merged_objects = self._merge_buildings()

        if self.replace_pred_roof:
            print("========== replace roof prediction with groundtruth ==========")
            self._replace_pred_roof_with_gt_roof(gt_roof_csv_file)

        if self.replace_pred_offset:
            print("========== replace roof prediction with groundtruth ==========")
            self._replace_pred_offset_with_gt_offset(gt_roof_csv_file)

        print("Finish init the pkl parser")

    def _replace_pred_roof_with_gt_roof(self, gt_roof_csv_file):
        gt_csv_parser = bstool.CSVParse(gt_roof_csv_file)
        gt_objects = gt_csv_parser.objects
        ori_image_name_list = gt_csv_parser.image_name_list

        for ori_image_name in self.ori_image_name_list:
            buildings = dict()

            gt_buildings = gt_objects[ori_image_name]
            pred_buildings = self.merged_objects[ori_image_name]

            gt_polygons = [gt_building["polygon"] for gt_building in gt_buildings]
            pred_polygons = [building["roof_polygon"] for building in pred_buildings]
            offsets = [building["offset"] for building in pred_buildings]

            gt_polygons_origin = gt_polygons[:]

            if len(gt_polygons) == 0 or len(pred_polygons) == 0:
                continue

            gt_polygons = geopandas.GeoSeries(gt_polygons)
            pred_polygons = geopandas.GeoSeries(pred_polygons)

            gt_df = geopandas.GeoDataFrame(
                {"geometry": gt_polygons, "gt_df": range(len(gt_polygons))}
            )
            pred_df = geopandas.GeoDataFrame(
                {"geometry": pred_polygons, "pred_df": range(len(pred_polygons))}
            )

            gt_df = gt_df.loc[~gt_df.geometry.is_empty]
            pred_df = pred_df.loc[~pred_df.geometry.is_empty]

            res_intersection = geopandas.overlay(gt_df, pred_df, how="intersection")

            iou = np.zeros((len(pred_polygons), len(gt_polygons)))
            for idx, row in res_intersection.iterrows():
                gt_idx = row.gt_df
                pred_idx = row.pred_df

                inter = row.geometry.area
                union = pred_polygons[pred_idx].area + gt_polygons[gt_idx].area

                iou[pred_idx, gt_idx] = inter / (union - inter + 1.0)

            replace_index = np.argmax(iou, axis=-1)
            new_pred_polygons = np.array(gt_polygons_origin)[replace_index].tolist()

            buildings = self.merged_objects[ori_image_name]
            num_buildings = len(buildings)
            for index in range(num_buildings):
                self.merged_objects[ori_image_name][index]["roof_polygon"] = new_pred_polygons[
                    index
                ]

            for idx, (offset, roof_polygon) in enumerate(zip(offsets, new_pred_polygons)):
                transform_matrix = [1, 0, 0, 1, -1.0 * offset[0], -1.0 * offset[1]]
                footprint_polygon = affinity.affine_transform(roof_polygon, transform_matrix)

                self.merged_objects[ori_image_name][idx]["footprint_polygon"] = footprint_polygon

    def _replace_pred_offset_with_gt_offset(self, gt_roof_csv_file):
        gt_csv_parser = bstool.CSVParse(gt_roof_csv_file)
        gt_objects = gt_csv_parser.objects
        ori_image_name_list = gt_csv_parser.image_name_list

        for ori_image_name in self.ori_image_name_list:
            buildings = dict()

            gt_buildings = gt_objects[ori_image_name]
            pred_buildings = self.merged_objects[ori_image_name]

            gt_polygons = [gt_building["polygon"] for gt_building in gt_buildings]
            gt_offsets = [gt_building["offset"] for gt_building in gt_buildings]
            pred_polygons = [building["roof_polygon"] for building in pred_buildings]
            offsets = [building["offset"] for building in pred_buildings]

            gt_polygons_origin = gt_polygons[:]

            if len(gt_polygons) == 0 or len(pred_polygons) == 0:
                continue

            gt_polygons = geopandas.GeoSeries(gt_polygons)
            pred_polygons = geopandas.GeoSeries(pred_polygons)

            gt_df = geopandas.GeoDataFrame(
                {"geometry": gt_polygons, "gt_df": range(len(gt_polygons))}
            )
            pred_df = geopandas.GeoDataFrame(
                {"geometry": pred_polygons, "pred_df": range(len(pred_polygons))}
            )

            gt_df = gt_df.loc[~gt_df.geometry.is_empty]
            pred_df = pred_df.loc[~pred_df.geometry.is_empty]

            res_intersection = geopandas.overlay(gt_df, pred_df, how="intersection")

            iou = np.zeros((len(pred_polygons), len(gt_polygons)))
            for idx, row in res_intersection.iterrows():
                gt_idx = row.gt_df
                pred_idx = row.pred_df

                inter = row.geometry.area
                union = pred_polygons[pred_idx].area + gt_polygons[gt_idx].area

                iou[pred_idx, gt_idx] = inter / (union - inter + 1.0)

            replace_index = np.argmax(iou, axis=-1)
            new_pred_polygons = np.array(gt_polygons_origin)[replace_index].tolist()
            new_pred_offsets = np.array(gt_offsets)[replace_index].tolist()

            buildings = self.merged_objects[ori_image_name]
            num_buildings = len(buildings)
            # for index in range(num_buildings):
            #     self.merged_objects[ori_image_name][index]['roof_polygon'] = new_pred_polygons[index]

            for idx, (offset, roof_polygon) in enumerate(zip(new_pred_offsets, pred_polygons)):
                transform_matrix = [1, 0, 0, 1, -1.0 * offset[0], -1.0 * offset[1]]
                footprint_polygon = affinity.affine_transform(roof_polygon, transform_matrix)

                self.merged_objects[ori_image_name][idx]["footprint_polygon"] = footprint_polygon

    def _merge_buildings(self):
        self.ori_image_name_list = list(self.building_with_coord.keys())

        merged_objects = dict()
        for ori_image_name in self.ori_image_name_list:
            subimage_coordinates = self.building_with_coord[ori_image_name]

            merged_buildings = []
            polygons_merged, scores_merged = [], []
            for subimage_coordinate in subimage_coordinates:
                buildings = self.building_with_coord[ori_image_name][subimage_coordinate].copy()

                if len(buildings) == 0:
                    continue

                buildings = self._chang_building_coordinate(buildings, subimage_coordinate)
                merged_buildings += buildings

                footprint_polygons = [building["footprint_polygon"] for building in buildings]
                scores = [building["score"] for building in buildings]

                polygons_merged += footprint_polygons
                scores_merged += scores

            keep = self._mask_nms(
                polygons_merged, np.array(scores_merged), iou_threshold=self.iou_threshold
            )

            merged_objects[ori_image_name] = np.array(merged_buildings)[keep].tolist()

        return merged_objects

    def _chang_building_coordinate(self, buildings, coordinate):
        transform_matrix = [1, 0, 0, 1, coordinate[0], coordinate[1]]

        transformed_buildings = []
        for building in buildings:
            roof_polygon = building["roof_polygon"]
            footprint_polygon = building["footprint_polygon"]

            transformed_roof_polygon = affinity.affine_transform(roof_polygon, transform_matrix)
            transformed_footprint_polygon = affinity.affine_transform(
                footprint_polygon, transform_matrix
            )
            building["roof_polygon"] = transformed_roof_polygon
            building["footprint_polygon"] = transformed_footprint_polygon

            transformed_buildings.append(building)

        return transformed_buildings

    def _mask_nms(self, masks, scores, iou_threshold=0.5):
        """non-maximum suppression (NMS) on the masks according to their intersection-over-union (IoU)

        Arguments:
            masks {np.array} -- [N * 4]
            scores {np.array} -- [N * 1]
            iou_threshold {float} -- threshold for IoU
        """
        polygons = np.array(masks)

        areas = np.array([polygon.area for polygon in polygons])

        order = scores.argsort()[::-1]

        keep = []
        while order.size > 0:
            best_mask_idx = order[0]
            keep.append(best_mask_idx)

            best_mask = polygons[best_mask_idx]
            remain_masks = polygons[order[1:]]

            inters = []
            for remain_mask in remain_masks:
                mask1 = best_mask
                mask2 = remain_mask
                try:
                    inter = mask1.intersection(mask2).area
                except:
                    inter = 2048 * 2048
                inters.append(inter)

            inters = np.array(inters)
            iou = inters / (areas[best_mask_idx] + areas[order[1:]] - inters)

            inds = np.where(iou <= iou_threshold)[0]

            order = order[inds + 1]

        return keep

    def _convert_items(self, result):
        """convert the result to dict format

        Args:
            result (list): detection result

        Raises:
            NotImplementedError: [description]

        Returns:
            dict: result with dict format
        """
        buildings = []
        if self.with_offset and not self.with_height:
            # det, seg, offset = result # origin
            # det, seg, offset = result[0], result[1], result[2]
            if result[3] is not None and result[5] is not None:
                det, seg, offset, height, direct_foot_seg = (
                    result[0],
                    result[1],
                    result[2],
                    result[3],
                    result[5],
                )
            elif result[3] is not None and result[5] is None:
                det, seg, offset, height = result[0], result[1], result[2], result[3]
                direct_foot_seg = seg
            elif result[3] is None and result[5] is not None:
                det, seg, offset, direct_foot_seg = result[0], result[1], result[2], result[5]
                height = np.zeros((offset.shape[0], 1))
            else:
                det, seg, offset = result[0], result[1], result[2]
                height = np.zeros((offset.shape[0], 1))
                direct_foot_seg = seg

            # det, seg, offset, height = result[0], result[1], result[2], result[3]
            # det, seg, offset = result[0][0][0], result[1][0], result[2][0]
        #     if isinstance(offset, list):
        #         return []
        #     else:
        #         # height = np.zeros((offset.shape[0], 1))
        #         height = np.ones((offset.shape[0], 1))
        # if self.with_height:
        #     det, seg, offset, height = result

        bboxes = np.vstack(det)
        segms = mmcv.concat_list(seg)
        direct_foot_segs = mmcv.concat_list(direct_foot_seg)

        if isinstance(offset, tuple):
            offsets = offset[0]
        else:
            offsets = offset

        if self.with_height and isinstance(height, tuple):
            heights = height[0]
        else:
            heights = height

        for i in range(bboxes.shape[0]):
            building = dict()
            score = bboxes[i][4]
            if score < self.score_threshold:
                continue
            # convert direct footprint
            if isinstance(direct_foot_segs[i]["counts"], bytes):
                direct_foot_segs[i]["counts"] = direct_foot_segs[i]["counts"].decode()
            mask_foot = maskUtils.decode(direct_foot_segs[i]).astype(np.bool)
            gray_foot = np.array(mask_foot * 255, dtype=np.uint8)

            contours_foot = cv2.findContours(
                gray_foot.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
            )
            contours_foot = contours_foot[0] if len(contours_foot) == 2 else contours_foot[1]

            if contours_foot != [] and len(contours_foot) > 0:
                cnt_foot = max(contours_foot, key=cv2.contourArea)
                if cv2.contourArea(cnt_foot) < 5:
                    continue
                mask_foot = np.array(cnt_foot).reshape(1, -1).tolist()[0]
                if len(mask_foot) < 8:
                    continue

                valid_flag_foot = bstool.single_valid_polygon(bstool.mask2polygon(mask_foot))
                if not valid_flag_foot:
                    polygon_foot = bstool.mask2polygon(mask_foot).buffer(0)
                    if polygon_foot.geom_type == "MultiPolygon":
                        continue
                    else:
                        if polygon_foot.exterior is None:
                            continue
                        else:
                            mask_foot = bstool.polygon2mask(polygon_foot)
                    # continue
            else:
                continue

            # convert the original segmentation result to polygon format
            if isinstance(segms[i]["counts"], bytes):
                segms[i]["counts"] = segms[i]["counts"].decode()
            mask = maskUtils.decode(segms[i]).astype(np.bool)
            gray = np.array(mask * 255, dtype=np.uint8)

            contours = cv2.findContours(gray.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            contours = contours[0] if len(contours) == 2 else contours[1]

            if contours != [] and len(contours) > 0:
                cnt = max(contours, key=cv2.contourArea)
                if cv2.contourArea(cnt) < 5:
                    continue
                mask = np.array(cnt).reshape(1, -1).tolist()[0]
                if len(mask) < 8:
                    continue

                valid_flag = bstool.single_valid_polygon(bstool.mask2polygon(mask))
                if not valid_flag:
                    polygon_ = bstool.mask2polygon(mask).buffer(0)
                    if polygon_.geom_type == "MultiPolygon":
                        continue
                    else:
                        if polygon_.exterior is None:
                            continue
                        else:
                            mask = bstool.polygon2mask(polygon_)
                    # continue
            else:
                continue

            bbox = bboxes[i][0:4]
            offset = offsets[i]
            height = heights[i][0]
            roof = mask

            roof_polygon = bstool.mask2polygon(roof)

            if roof_polygon.area < self.min_area:
                continue

            # convert the roof polygon to footprint polygon
            if self.offset_model == "footprint2roof":
                transform_matrix = [1, 0, 0, 1, -1.0 * offset[0], -1.0 * offset[1]]
            elif self.offset_model == "roof2footprint":
                transform_matrix = [1, 0, 0, 1, 1.0 * offset[0], 1.0 * offset[1]]
            else:
                raise NotImplementedError
            footprint_polygon = affinity.affine_transform(roof_polygon, transform_matrix)

            direct_footprint = mask_foot
            direct_footprint_polygon = bstool.mask2polygon(direct_footprint)
            if direct_footprint_polygon.area < self.min_area:
                continue

            building["bbox"] = bbox.tolist()
            building["offset"] = offset.tolist()
            building["height"] = height
            building["score"] = score
            building["roof_polygon"] = roof_polygon
            building["footprint_polygon"] = footprint_polygon
            building["direct_footprint_polygon"] = direct_footprint_polygon

            buildings.append(building)

        return buildings

    def __call__(self, image_fn, splitted=False):
        if splitted:
            if image_fn in self.objects.keys():
                return self.objects[image_fn]
            else:
                print("{} is not in pkl".format(image_fn))
                return []
        else:
            if image_fn in self.merged_objects.keys():
                return self.merged_objects[image_fn]
            else:
                print("{} is not in pkl".format(image_fn))
                return []


class BSPklParser_Only_Offset(BSPklParser):
    """parse the results which have only offset information

    Args:
        BSPklParser (class): original pkl parse class
    """

    def _convert_items(self, result):
        buildings = []
        det, offset = result

        bboxes = np.vstack(det)

        if isinstance(offset, tuple):
            offsets = offset[0]
        else:
            offsets = offset

        for i in range(bboxes.shape[0]):
            building = dict()
            score = bboxes[i][4]
            if score < self.score_threshold:
                continue

            bbox = bboxes[i][0:4]
            bbox = bbox.tolist()
            offset = offsets[i]

            w = bbox[2] - bbox[0]
            h = bbox[3] - bbox[1]

            if w < 2 or h < 2:
                continue

            if bbox[0] < 0 or bbox[1] > 1023 or bbox[2] < 0 or bbox[3] > 1023:
                continue

            roof = bstool.bbox2pointobb(bbox)  # fake roof

            roof_polygon = bstool.mask2polygon(roof)

            valid_flag = bstool.single_valid_polygon(roof_polygon)
            if not valid_flag:
                continue

            if roof_polygon.area < self.min_area:
                continue

            building["bbox"] = bbox
            building["offset"] = offset.tolist()
            building["height"] = 0.0
            building["score"] = score
            building["roof_polygon"] = roof_polygon
            building["footprint_polygon"] = roof_polygon

            buildings.append(building)

        return buildings


class BSPklParser_Without_Offset(BSPklParser):
    """parse the result which without offset information

    Args:
        BSPklParser (class): original pkl parse class
    """

    def _convert_items(self, result):
        buildings = []
        det, seg = result[0], result[1]

        bboxes = np.vstack(det)
        segms = mmcv.concat_list(seg)

        for i in range(bboxes.shape[0]):
            building = dict()
            score = bboxes[i][4]
            if score < self.score_threshold:
                continue

            if isinstance(segms[i]["counts"], bytes):
                segms[i]["counts"] = segms[i]["counts"].decode()
            mask = maskUtils.decode(segms[i]).astype(np.bool)
            gray = np.array(mask * 255, dtype=np.uint8)

            contours = cv2.findContours(gray.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            contours = contours[0] if len(contours) == 2 else contours[1]

            if contours != [] and len(contours) > 0:
                cnt = max(contours, key=cv2.contourArea)
                if cv2.contourArea(cnt) < 5:
                    continue
                mask = np.array(cnt).reshape(1, -1).tolist()[0]
                if len(mask) < 8:
                    continue

                valid_flag = bstool.single_valid_polygon(bstool.mask2polygon(mask))
                if not valid_flag:
                    continue
            else:
                continue

            bbox = bboxes[i][0:4]
            bbox = bbox.tolist()
            roof = mask

            w = bbox[2] - bbox[0]
            h = bbox[3] - bbox[1]

            if w < 2 or h < 2:
                continue

            if bbox[0] < 0 or bbox[1] > 1023 or bbox[2] < 0 or bbox[3] > 1023:
                continue

            # roof = bstool.bbox2pointobb(bbox)   # fake roof

            roof_polygon = bstool.mask2polygon(roof)

            valid_flag = bstool.single_valid_polygon(roof_polygon)
            if not valid_flag:
                continue

            if roof_polygon.area < self.min_area:
                continue

            building["bbox"] = bbox
            building["height"] = 0.0
            building["offset"] = [0, 0]
            building["score"] = score
            building["roof_polygon"] = roof_polygon
            building["footprint_polygon"] = roof_polygon
            building["direct_footprint_polygon"] = roof_polygon

            buildings.append(building)

        return buildings

    def _merge_buildings(self):
        self.ori_image_name_list = list(self.building_with_coord.keys())

        merged_objects = dict()
        for ori_image_name in self.ori_image_name_list:
            subimage_coordinates = self.building_with_coord[ori_image_name]

            merged_buildings = []
            polygons_merged, scores_merged = [], []
            for subimage_coordinate in subimage_coordinates:
                buildings = self.building_with_coord[ori_image_name][subimage_coordinate]

                if len(buildings) == 0:
                    continue

                merged_buildings += buildings

                roof_polygons = [building["roof_polygon"] for building in buildings]
                scores = [building["score"] for building in buildings]

                polygons_merged += roof_polygons
                scores_merged += scores

            keep = self._mask_nms(
                polygons_merged, np.array(scores_merged), iou_threshold=self.iou_threshold
            )

            merged_objects[ori_image_name] = np.array(merged_buildings)[keep].tolist()

        return merged_objects


class CSVParse:
    """parse csv file by pandas, save the data of csv file to dict"""

    def __init__(self, csv_file, min_area=10, check_valid=True):
        csv_df = pandas.read_csv(csv_file)
        self.image_name_list = list(set(csv_df.ImageId.unique()))

        self.objects = defaultdict(dict)
        self.dataset_buildings = []
        print(f"begin parsing the csv file: {csv_file}")
        object_count = [0, 0]
        for image_name in tqdm.tqdm(self.image_name_list):
            buildings = []
            for idx, row in csv_df[csv_df.ImageId == image_name].iterrows():
                object_count[0] += 1
                building = dict()
                obj_keys = row.to_dict().keys()
                polygon = shapely.wkt.loads(row.PolygonWKT_Pix)
                if polygon.area < min_area:
                    continue
                building["polygon"] = polygon
                building["mask"] = bstool.polygon2mask(polygon)

                if check_valid and not bstool.single_valid_polygon(building["polygon"]):
                    building["polygon"] = building["polygon"].buffer(0)
                    if building["polygon"].geom_type == "MultiPolygon":
                        continue

                building["score"] = row.Confidence
                if "Offset" in obj_keys:
                    if type(row.Offset) == str:
                        if row.Offset == "[0 0]":
                            building["offset"] = [0, 0]
                        else:
                            building["offset"] = ast.literal_eval(row.Offset)
                    else:
                        building["offset"] = row.Offset
                else:
                    building["offset"] = [0, 0]

                if "Height" in obj_keys:
                    building["height"] = row.Height
                else:
                    building["height"] = 0

                buildings.append(building)
                object_count[1] += 1

            self.objects[image_name] = buildings
            self.dataset_buildings += buildings

        self.image_fns = self.objects.keys()
        print("This CSV has object number: ", object_count)

    def __call__(self, image_fn):
        if image_fn in self.objects.keys():
            return self.objects[image_fn]
        else:
            print("{} is not in csv file".format(image_fn))
            return []
